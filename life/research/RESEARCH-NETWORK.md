# Dub & Donny Research Network
## Learning Flywheel â€” Grow, Curate, Compound

**Mission:** Build a self-improving intelligence network across Reddit + X that surfaces valuable insights daily while growing our reach.

---

## ğŸ“¡ Platforms

### Reddit (u/Ok_Flounder_438)
- Browser-based scanning (FREE, no API)
- Subscribe to subs â†’ content comes to us
- old.reddit.com for cleaner parsing

### X (@ClawdChad)
- Browser-based scanning (FREE, no API)
- Follow key accounts â†’ content comes to us
- Engage selectively to grow reach

---

## ğŸ¯ Topic Verticals

### 1. AI & Local Models
**Reddit:**
- r/LocalLLaMA â­ (primary)
- r/MachineLearning
- r/artificial
- r/ClaudeAI
- r/ChatGPT
- r/Ollama
- r/StableDiffusion

**X Accounts:** (see x-signal-accounts.md)

### 2. Tech & Automation
**Reddit:**
- r/selfhosted
- r/homelab
- r/programming
- r/automation
- r/n8n
- r/homeassistant

### 3. Robotics & Hardware
**Reddit:**
- r/robotics
- r/3Dprinting
- r/arduino
- r/raspberry_pi
- r/FPGA

### 4. Finance & Trading
**Reddit:**
- r/options â­
- r/thetagang
- r/algotrading
- r/wallstreetbets (noise but signals)
- r/stocks
- r/cryptocurrency
- r/Bitcoin

### 5. Business & SaaS (Grant Nexus intel)
**Reddit:**
- r/SaaS
- r/startups
- r/Entrepreneur
- r/HigherEducation
- r/AskAcademia

---

## ğŸ“Š Scanning Protocol

### Morning Scan (6:00 AM, before brief)
1. Check Reddit front page of subscribed subs
2. Check X feed for overnight posts
3. Extract top 3-5 valuable items per vertical
4. Summarize with LOCAL LLM (save tokens)
5. Store in `memory/research/YYYY-MM-DD.md`
6. Include highlights in morning brief

### Afternoon Scan (2:30 PM, before 3 PM brief)
1. Check for midday developments
2. Focus on actionable intel (market moves, new releases)
3. Quick local LLM summary
4. Include in afternoon brief

### Deep Dive (Weekly, Sunday)
1. Review week's research notes
2. Identify patterns and trends
3. Update follow lists (add valuable, drop noise)
4. Synthesize key learnings to MEMORY.md

---

## ğŸ”§ Token Efficiency Rules

1. **Browser scraping** â†’ FREE (no API)
2. **Local LLM summarization** â†’ FREE (Ollama)
3. **Claude only for:**
   - Final brief synthesis
   - Complex analysis
   - User interaction
4. **Store raw data** â†’ Process locally later
5. **Batch processing** â†’ Summarize multiple items at once

### Local Models Available
- `qwen3:4b` â€” fast, good for summaries
- `llama3.2` â€” general purpose
- Use `~/bin/x-scout` and similar tools

---

## ğŸ“ˆ Growth Strategy

### Reddit
- [ ] Subscribe to all target subs
- [ ] Engage with valuable posts (upvote, occasional comment)
- [ ] Build karma gradually
- [ ] Eventually can post our own content

### X (@ClawdChad)
- [ ] Follow all Tier 1 + Tier 2 accounts
- [ ] Like/repost valuable content
- [ ] Build follower base through engagement
- [ ] Curated content â†’ attracts similar minds

---

## ğŸ“ File Structure

```
memory/research/
â”œâ”€â”€ YYYY-MM-DD.md      # Daily raw findings
â”œâ”€â”€ weekly-synthesis.md # Weekly patterns
â””â”€â”€ insights/          # Evergreen learnings
    â”œâ”€â”€ ai-models.md
    â”œâ”€â”€ trading.md
    â””â”€â”€ saas.md
```

---

## ğŸ¯ Success Metrics

**30-day goals:**
- Reddit: Subscribed to 20+ relevant subs
- X: Following 50+ valuable accounts
- Daily briefs: Consistently delivering value
- Knowledge: Measurable improvement in insights

**90-day goals:**
- Reddit karma: 100+
- X followers: 500+
- Research database: Rich and searchable
- Pattern recognition: Identifying trends early

---

*This network compounds daily. Every scan makes us smarter.*
